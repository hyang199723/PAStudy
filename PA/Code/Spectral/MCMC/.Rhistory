set.seed(42)
library(sand)
data(ppi.CC)
summary(ppi.CC)
library(kernlab)
library(caret)
# Get largest component
clu <- components(ppi.CC)
ppi.CC.gc <- induced_subgraph(ppi.CC, clu$membership==which.max(clu$csize))
summary(ppi.CC.gc)
X <- V(ppi.CC.gc)$ICSC
# Construct kernel
L <- as.matrix(laplacian_matrix(ppi.CC.gc))
e.L <- eigen(L)
nv <- vcount(ppi.CC.gc)
e.vals <- e.L$values[1:(nv-1)]
f.e.vals <- c((e.vals)^(-1), 0)
K1.tmp <- e.L$vectors %*% diag(f.e.vals) %*% t(e.L$vectors)
K1 <- as.kernelMatrix(K1.tmp)
# Fit the model
m1.svm <- ksvm(K1, X, type="nu-svc", nu = 0.01, prob.model = TRUE)
m1.svm.fitted <- fitted(m1.svm)
m1.svm.fitted
m1.svm
View(m1.svm)
m1.svm$coef
m1.svm['coef']
predict(m1.svm, K1, type = 'prob')
prob = predict(m1.svm, K1, type = 'prob')
cvAUC(prob, X)
prob[, 1]
prob = prob[, 1]
cvAUC(prob, X)
cvAUC(prob, X)
#Plot fold AUCs
plot(out$perf, col="grey82", lty=3, main="10-fold CV AUC")
out = cvAUC(prob, X)
#Plot fold AUCs
plot(out$perf, col="grey82", lty=3, main="10-fold CV AUC")
#Plot CV AUC
plot(out$perf, col="red", avg="vertical", add=TRUE)
prob = prob[, 0]
prob = prob[, 2]
prob = predict(m1.svm, K1, type = 'prob')
prob
prob = predict(m1.svm, K1, type = 'prob')
prob = prob[, 2]
out = cvAUC(prob, X)
#Plot fold AUCs
plot(out$perf, col="grey82", lty=3, main="10-fold CV AUC")
#Plot CV AUC
plot(out$perf, col="red", avg="vertical", add=TRUE)
prob = predict(m1.svm, K1, type = 'prob')
prob = prob[, 1]
out = cvAUC(prob, X)
#Plot fold AUCs
plot(out$perf, col="grey82", lty=3, main="10-fold CV AUC")
#Plot CV AUC
plot(out$perf, col="red", avg="vertical", add=TRUE)
# Fit the model
m1.svm <- ksvm(K1, X, type="C-svc", prob.model = TRUE)
prob = predict(m1.svm, K1, type = 'prob')
prob = prob[, 1]
out = cvAUC(prob, X)
#Plot fold AUCs
plot(out$perf, col="grey82", lty=3, main="10-fold CV AUC")
#Plot CV AUC
plot(out$perf, col="red", avg="vertical", add=TRUE)
prob = prob[, 2]
out = cvAUC(prob, X)
prob = predict(m1.svm, K1, type = 'prob')
prob = prob[, 2]
out = cvAUC(prob, X)
#Plot fold AUCs
plot(out$perf, col="grey82", lty=3, main="10-fold CV AUC")
#Plot CV AUC
plot(out$perf, col="red", avg="vertical", add=TRUE)
L <- as.matrix(laplacian_matrix(ppi.CC.gc))
e.L <- eigen(L)
nv <- vcount(ppi.CC.gc)
e.vals <- e.L$values[1:(nv-1)]
f.e.vals <- c((e.vals)^(-1), 0)
K1.tmp <- e.L$vectors %*% diag(f.e.vals) %*% t(e.L$vectors)
K1 <- as.kernelMatrix(K1.tmp)
# Fit the model
m1.svm <- ksvm(K1, X, type="C-svc", prob.model = TRUE)
prob = predict(m1.svm, K1, type = 'prob')
prob = prob[, 2]
out = cvAUC(prob, X)
plot(out$perf, col="red", avg="vertical", add=TRUE)
# Original network: 134 vertices and 241 edges
# Analysis network: largest component
#   - 127 vertives, 70 labled and 51 not labeled
# 10-fold cross validation used: 90% training, 10% testing
# Goal: Replicate kernel logistic regression
# Kernel is generated based on Laplacian matrix of the graph
rm(list = ls())
set.seed(42)
library(sand)
data(ppi.CC)
summary(ppi.CC)
library(kernlab)
library(caret)
library(cvAUC)
# Get largest component
clu <- components(ppi.CC)
ppi.CC.gc <- induced_subgraph(ppi.CC, clu$membership==which.max(clu$csize))
summary(ppi.CC.gc)
X <- V(ppi.CC.gc)$ICSC
# Construct kernel
L <- as.matrix(laplacian_matrix(ppi.CC.gc))
e.L <- eigen(L)
nv <- vcount(ppi.CC.gc)
e.vals <- e.L$values[1:(nv-1)]
f.e.vals <- c((e.vals)^(-1), 0)
K1.tmp <- e.L$vectors %*% diag(f.e.vals) %*% t(e.L$vectors)
K1 <- as.kernelMatrix(K1.tmp)
# Fit the model
m1.svm <- ksvm(K1, X, type="C-svc", prob.model = TRUE)
prob = predict(m1.svm, K1, type = 'prob')
prob = prob[, 2]
out = cvAUC(prob, X)
plot(out$perf, col="blue", avg="vertical")
# Original network: 134 vertices and 241 edges
# Analysis network: largest component
#   - 127 vertives, 70 labled and 51 not labeled
# 10-fold cross validation used: 90% training, 10% testing
# Goal: Replicate kernel logistic regression
# Kernel is generated based on Laplacian matrix of the graph
rm(list = ls())
set.seed(42)
library(sand)
data(ppi.CC)
summary(ppi.CC)
library(kernlab)
library(caret)
library(cvAUC)
# Get largest component
clu <- components(ppi.CC)
ppi.CC.gc <- induced_subgraph(ppi.CC, clu$membership==which.max(clu$csize))
summary(ppi.CC.gc)
X <- V(ppi.CC.gc)$ICSC
# Construct kernel
L <- as.matrix(laplacian_matrix(ppi.CC.gc))
e.L <- eigen(L)
nv <- vcount(ppi.CC.gc)
e.vals <- e.L$values[1:(nv-1)]
f.e.vals <- c((e.vals)^(-1), 0)
K1.tmp <- e.L$vectors %*% diag(f.e.vals) %*% t(e.L$vectors)
K1 <- as.kernelMatrix(K1.tmp)
# Fit the model
m1.svm <- ksvm(K1, X, type="C-svc", prob.model = TRUE)
prob = predict(m1.svm, K1, type = 'prob')
prob = prob[, 2]
out = cvAUC(prob, X)
plot(out$perf, col="blue", avg="vertical", title = '10-fold auc curve')
# Original network: 134 vertices and 241 edges
# Analysis network: largest component
#   - 127 vertives, 70 labled and 51 not labeled
# 10-fold cross validation used: 90% training, 10% testing
# Goal: Replicate kernel logistic regression
# Kernel is generated based on Laplacian matrix of the graph
rm(list = ls())
set.seed(42)
library(sand)
data(ppi.CC)
summary(ppi.CC)
library(kernlab)
library(caret)
library(cvAUC)
# Get largest component
clu <- components(ppi.CC)
ppi.CC.gc <- induced_subgraph(ppi.CC, clu$membership==which.max(clu$csize))
summary(ppi.CC.gc)
X <- V(ppi.CC.gc)$ICSC
# Construct kernel
L <- as.matrix(laplacian_matrix(ppi.CC.gc))
e.L <- eigen(L)
nv <- vcount(ppi.CC.gc)
e.vals <- e.L$values[1:(nv-1)]
f.e.vals <- c((e.vals)^(-1), 0)
K1.tmp <- e.L$vectors %*% diag(f.e.vals) %*% t(e.L$vectors)
K1 <- as.kernelMatrix(K1.tmp)
# Fit the model
m1.svm <- ksvm(K1, X, type="C-svc", prob.model = TRUE)
prob = predict(m1.svm, K1, type = 'prob')
prob = prob[, 2]
out = cvAUC(prob, X)
plot(out$perf, col="blue", avg="vertical", main = '10-fold auc curve')
# Original network: 134 vertices and 241 edges
# Analysis network: largest component
#   - 127 vertives, 70 labled and 51 not labeled
# 10-fold cross validation used: 90% training, 10% testing
# Goal: Replicate kernel logistic regression
# Kernel is generated based on Laplacian matrix of the graph
rm(list = ls())
set.seed(42)
library(sand)
data(ppi.CC)
summary(ppi.CC)
library(kernlab)
library(caret)
library(cvAUC)
# Get largest component
clu <- components(ppi.CC)
ppi.CC.gc <- induced_subgraph(ppi.CC, clu$membership==which.max(clu$csize))
summary(ppi.CC.gc)
X <- V(ppi.CC.gc)$ICSC
# Construct kernel
L <- as.matrix(laplacian_matrix(ppi.CC.gc))
e.L <- eigen(L)
nv <- vcount(ppi.CC.gc)
e.vals <- e.L$values[1:(nv-1)]
f.e.vals <- c((e.vals)^(-1), 0)
K1.tmp <- e.L$vectors %*% diag(f.e.vals) %*% t(e.L$vectors)
K1 <- as.kernelMatrix(K1.tmp)
# Fit the model
m1.svm <- ksvm(K1, X, type="C-svc", prob.model = TRUE)
prob = predict(m1.svm, K1, type = 'prob')
prob = prob[, 2]
out = cvAUC(prob, X)
plot(out$perf, col="blue", avg="vertical", main = '10-fold auc curve')
install.packages("cmna")
x1 <- c(1,2,3)
polyroot(x1)
r1 = polyroot(x1)
r1[1]
r1[2]
wilkinson(w = 20)
library(cmna)
wilkinson(w = 20)
wilkinson(1, w = 20)
# Poly number 1 - 7: Wilkinson and its variants
w1 <- c(28800, -10628640, 12753576, -8409500, 3416930, -902055, 157773, -18150, 1320, -55, 1)
r1 = polyroot(x1)
r1 = polyroot(w11)
rm(list = ls())
# Poly number 1 - 7: Wilkinson and its variants
w1 <- c(28800, -10628640, 12753576, -8409500, 3416930, -902055, 157773, -18150, 1320, -55, 1)
r1 = polyroot(w1)
r1
install.packages("pracma")
library(pracma)
polyval(w1, 1)
polyval(w1, 1-1e-3)
polyval(w1, 1+1e-3)
w1
reverse(w1)
rev(w1)
polyval(rev(w1), 1+1e-3)
polyval(rev(w1), 1)
rev(w1)
polyval(rev(w1), 1-e-4)
polyval(rev(w1), 1-0.0001)
polyval(rev(w1), 1+0.0001)
polyroot(w1)
w1
# Poly number 1 - 7: Wilkinson and its variants
w1 <- c(3628800, -10628640, 12753576, -8409500, 3416930, -902055, 157773, -18150, 1320, -55, 1)
r1 = polyroot(w1)
polyval(rev(w1), 1+0.0001)
polyval(rev(w1), 1-0.0001)
polyval(rev(w1), 1)
r1 = polyroot(w1)
r1
w2 <- c(-1307674368000, 4339163001600, -6165817614720, 5056995703824,
-2706813345600, 1009672107080, -272803210680, 54631129553,
-8207628000, 928095740, -78558480, 4899622, -218400, 6580, -120, 1)
r2 = polyroot(w2)
polyval(rev(w2), 1)
r2
rm(list = ls())
library(fields)
library(geoR)
library(truncnorm)
library(tidyverse)
library(mvtnorm)
library(gridExtra)
setwd("/Users/hongjianyang/Research/PAStudy/PA/Code/Spectral/MCMC/")
source('ExtraFunctions.R')
source('LMC_function.R')
#simulate data
source('simAllTS.R') # load your data here
# names(out)=c('rangeU','rangeV','sigmaU','sigmaV','tau1','tau2','A','Y1.m','Y2.m','Y1p')
# Real data are Y1.real and Y2.real
# Coordinates are coords1 and coords2
iters = 3000
burn=1000
exit = LMC_fit(Y1=Y1.real,Y2=Y2.real, s1=coords1,s2=coords2,sp1=NULL,sp2=NULL,
mean_range=0, sd_range=1, mean_var=0, sd_var=1, mean_rho=0,
sd_rho=10, iters=iters, burn=burn, thin=1, update=10)
range1 = exit$rangeU
range2 = exit$rangeV
sigma1 = exit$sigmaU
sigma2 = exit$sigmaV
tau1 = exit$tau1
tau2 = exit$tau2
Al = exit$A
rm(list = ls())
library(fields)
library(geoR)
library(truncnorm)
library(tidyverse)
library(mvtnorm)
library(gridExtra)
setwd("/Users/hongjianyang/Research/PAStudy/PA/Code/Spectral/MCMC/")
source('ExtraFunctions.R')
source('LMC_function.R')
#simulate data
source('simAllTS.R') # load your data here
# names(out)=c('rangeU','rangeV','sigmaU','sigmaV','tau1','tau2','A','Y1.m','Y2.m','Y1p')
# Real data are Y1.real and Y2.real
# Coordinates are coords1 and coords2
iters = 3000
burn=1000
exit = LMC_fit(Y1=Y1.real,Y2=Y2.real, s1=coords1,s2=coords2,sp1=NULL,sp2=NULL,
mean_range=0, sd_range=1, mean_var=0, sd_var=1, mean_rho=0,
sd_rho=10, iters=iters, burn=burn, thin=1, update=10)
range1 = exit$rangeU
range2 = exit$rangeV
sigma1 = exit$sigmaU
sigma2 = exit$sigmaV
tau1 = exit$tau1
tau2 = exit$tau2
Al = exit$A
range11 = mean(range1)
range21 = range2[, 1]
sigma11 = sigma1[, , 1]
sigma21 = sigma2[, , 1]
sigma1mean = colMeans(t(sigma11))
sigma2mean = colMeans(t(sigma21))
tau11 = tau1[, 1]
tau21 = tau2[, 1]
A = Al[, 1]
Al
A = Al[,, 1]
A
View(A)
# Actual v.s. recovery
plot(1:3000, range1)
abline(rangeu,0,col=2,lwd=2)
# Actual v.s. recovery
plot(1:3000, 'l', range1)
# Actual v.s. recovery
plot(1:3000, range1, 'l')
abline(rangeu,0,col=2,lwd=2)
plot(1:3000, range2, 'l')
abline(rangev,0,col=2,lwd=2)
# Actual v.s. recovery
plot(1:3000, range1, 'l')
# Actual v.s. recovery
plot(1:3000, range1, 'l')
abline(rangeu,0,col=2,lwd=2)
plot(1:3000, range2, 'l')
abline(rangev,0,col=2,lwd=2)
rm(list = ls())
library(fields)
library(geoR)
library(truncnorm)
library(tidyverse)
library(mvtnorm)
library(gridExtra)
setwd("/Users/hongjianyang/Research/PAStudy/PA/Code/Spectral/MCMC/")
source('ExtraFunctions.R')
source('LMC_function.R')
#simulate data
source('simAllTS.R') # load your data here
# names(out)=c('rangeU','rangeV','sigmaU','sigmaV','tau1','tau2','A','Y1.m','Y2.m','Y1p')
# Real data are Y1.real and Y2.real
# Coordinates are coords1 and coords2
iters = 3000
burn=1000
exit = LMC_fit(Y1=Y1.real,Y2=Y2.real, s1=coords1,s2=coords2,sp1=NULL,sp2=NULL,
mean_range=0, sd_range=1, mean_var=0, sd_var=1, mean_rho=0,
sd_rho=10, iters=iters, burn=burn, thin=1, update=10)
range1 = exit$rangeU
range2 = exit$rangeV
sigma1 = exit$sigmaU
sigma2 = exit$sigmaV
tau1 = exit$tau1
tau2 = exit$tau2
Al = exit$A
range11 = mean(range1)
range21 = range2[, 1]
sigma11 = sigma1[, , 1]
sigma21 = sigma2[, , 1]
sigma1mean = colMeans(t(sigma11))
sigma2mean = colMeans(t(sigma21))
tau11 = tau1[, 1]
tau21 = tau2[, 1]
A = Al[,, 1]
# Actual v.s. recovery
plot(1:3000, range1, 'l')
abline(rangeu,0,col=2,lwd=2)
plot(1:3000, range2, 'l')
abline(rangev,0,col=2,lwd=2)
rm(list = ls())
library(fields)
library(geoR)
library(truncnorm)
library(tidyverse)
library(mvtnorm)
library(gridExtra)
setwd("/Users/hongjianyang/Research/PAStudy/PA/Code/Spectral/MCMC/")
source('ExtraFunctions.R')
source('LMC_function.R')
#simulate data
source('simAllTS.R') # load your data here
View(Y1.real)
Y11 = Y1.real[, 1]
Y21 = Y2.real[, 1]
cor(Y11, Y21)
View(Y1.real)
View(Y2.real)
rm(list = ls())
library(fields)
library(geoR)
library(truncnorm)
library(tidyverse)
library(mvtnorm)
library(gridExtra)
setwd("/Users/hongjianyang/Research/PAStudy/PA/Code/Spectral/MCMC/")
source('ExtraFunctions.R')
source('LMC_function.R')
#simulate data
source('simAllTS.R') # load your data here
Y11 = Y1.real[, 1]
Y21 = Y2.real[, 1]
cor(Y11, Y21)
View(Y1.real)
View(Y2.real)
rm(list = ls())
library(fields)
library(geoR)
library(truncnorm)
library(tidyverse)
library(mvtnorm)
library(gridExtra)
setwd("/Users/hongjianyang/Research/PAStudy/PA/Code/Spectral/MCMC/")
source('ExtraFunctions.R')
source('LMC_function.R')
#simulate data
source('simAllTS.R') # load your data here
Y11 = Y1.real[, 1]
Y21 = Y2.real[, 1]
cor(Y11, Y21)
rm(list = ls())
library(fields)
library(geoR)
library(truncnorm)
library(tidyverse)
library(mvtnorm)
library(gridExtra)
setwd("/Users/hongjianyang/Research/PAStudy/PA/Code/Spectral/MCMC/")
source('ExtraFunctions.R')
source('LMC_function.R')
#simulate data
source('simAllTS.R') # load your data here
Y11 = Y1.real[, 1]
Y21 = Y2.real[, 1]
cor(Y11, Y21)
rm(list = ls())
library(fields)
library(geoR)
library(truncnorm)
library(tidyverse)
library(mvtnorm)
library(gridExtra)
setwd("/Users/hongjianyang/Research/PAStudy/PA/Code/Spectral/MCMC/")
source('ExtraFunctions.R')
source('LMC_function.R')
#simulate data
source('simAllTS.R') # load your data here
Y11 = Y1.real[, 1]
Y21 = Y2.real[, 1]
cor(Y11, Y21)
View(Y1.real)
View(Y2.real)
fft_real <- function(dat,inverse=FALSE){
if(!inverse){
x  <- dat
n  <- length(x)
n2 <- floor(n/2)
y  <- fft(x,inverse=FALSE)
if(n%%2==0){
X1     <- Re(y)[1:(n2+1)]
X2     <- Im(y)[2:(n2)]
}
if(n%%2!=0){
X1     <- Re(y)[1:(n2+1)]
X2     <- Im(y)[2:(n2+1)]
}
out <- c(X1,X2)
}
if(inverse){
X  <- dat
n  <- length(X)
n2 <- floor(n/2)
if(n%%2==0){
Y1    <- c(X[1:(n2+1)],X[n2:2])
Y2    <- c(0,X[(n2+2):n],0,-X[n:(n2+2)])
}
if(n%%2!=0){
Y1    <- c(X[1:(n2+1)],X[(n2+1):2])
Y2    <- c(0,X[(n2+2):n],-X[n:(n2+2)])
}
y   <- complex(n, real = Y1, imaginary = Y2)
out <- Re(fft(y/n,inverse=TRUE))
}
return(out)}
a = rnorm(20)
fft(a)
